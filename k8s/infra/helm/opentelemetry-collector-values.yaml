# OpenTelemetry Collector Configuration
# Deploys a single collector instance to receive telemetry from applications
# and export to Prometheus (metrics) and Azure Monitor (traces/logs)

mode: deployment

# Single replica for dev environment
replicaCount: 1

# Resource limits
resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi

# Service configuration - exposes OTLP receivers
service:
  type: ClusterIP
  ports:
    otlp:
      enabled: true
      containerPort: 4317
      servicePort: 4317
      protocol: TCP
    otlp-http:
      enabled: true
      containerPort: 4318
      servicePort: 4318
      protocol: TCP
    metrics:
      enabled: true
      containerPort: 8888
      servicePort: 8888
      protocol: TCP

# OpenTelemetry Collector configuration
config:
  receivers:
    # OTLP receiver for gRPC (default port 4317)
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

  processors:
    # Batch processor to reduce number of outgoing requests
    batch:
      timeout: 10s
      send_batch_size: 1024

    # Memory limiter to prevent OOM
    memory_limiter:
      check_interval: 1s
      limit_mib: 400

  exporters:
    # Prometheus exporter - exposes metrics for Prometheus to scrape
    prometheus:
      endpoint: 0.0.0.0:8889

    # Logging exporter for debugging (outputs to collector logs)
    logging:
      loglevel: info

    # Azure Monitor exporter - placeholder for Phase 3.3 completion
    # Uncomment and configure when ready to send traces/logs to Azure
    # azuremonitor:
    #   instrumentation_key: "${APPLICATIONINSIGHTS_CONNECTION_STRING}"

  service:
    pipelines:
      # Traces pipeline: receive via OTLP, batch, and export
      traces:
        receivers: [otlp]
        processors: [memory_limiter, batch]
        exporters: [logging] # Add azuremonitor when configured

      # Metrics pipeline: receive via OTLP, batch, and expose for Prometheus
      metrics:
        receivers: [otlp]
        processors: [memory_limiter, batch]
        exporters: [prometheus, logging]

      # Logs pipeline: receive via OTLP, batch, and export
      logs:
        receivers: [otlp]
        processors: [memory_limiter, batch]
        exporters: [logging] # Add azuremonitor when configured

# ServiceMonitor for Prometheus to scrape OTEL Collector metrics
serviceMonitor:
  enabled: true
  namespace: otel-system
  interval: 30s
